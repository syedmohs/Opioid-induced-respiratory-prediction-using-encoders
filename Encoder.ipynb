{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad984f45-d0bd-4365-82c7-f68c83081e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa1f03-4cb6-4058-8a75-e5c1cebec2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('my_project_data.pkl')\n",
    "print(\"DataFrame loaded from file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3143cea-f3eb-4a84-b33a-dd9c5aff6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clean the data: Drop rows where the target flag is missing (empty/NaN)\n",
    "df_clean = df.dropna(subset=['respiratory_depression']).copy()\n",
    "\n",
    "print(f\"Original DataFrame size: {len(df)}\")\n",
    "print(f\"Cleaned DataFrame size (rows with a known flag): {len(df_clean)}\")\n",
    "print(\"\\nTarget Class Distribution:\")\n",
    "print(df_clean['respiratory_depression'].value_counts())\n",
    "\n",
    "# 2. Define X and y\n",
    "# X will be the list of clinical narratives\n",
    "X = df_clean['Clinical_Narrative'].tolist()\n",
    "# y will be the list of target flags (converted to integers)\n",
    "y = df_clean['respiratory_depression'].astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c9bec-8e36-47a9-8c3a-a1f4e80e0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: Separate out the Test Set (20%) and keep the rest for Training/Validation\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.20,  # 20% for testing\n",
    "    random_state=42, # for reproducibility\n",
    "    stratify=y       # crucial for imbalanced classification\n",
    ")\n",
    "\n",
    "# Second split: Separate the Training Set (80% of remaining) from the Validation Set (20% of remaining)\n",
    "# Since X_test is 20% of total, we need to split X_train_val (which is 80% of total)\n",
    "# 0.20 / 0.80 = 0.25, so we split the remaining 80% into 75% train and 25% val to get 60/20 total.\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val,\n",
    "    test_size=0.25,  # 25% of the train_val set = 20% of the total dataset\n",
    "    random_state=42,\n",
    "    stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Dataset Splits Summary:\")\n",
    "print(f\"Train set size: {len(X_train)} (approx 60% of total)\")\n",
    "print(f\"Validation set size: {len(X_val)} (approx 20% of total)\")\n",
    "print(f\"Test set size: {len(X_test)} (20% of total)\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915913d-042e-41d1-b870-685d782767de",
   "metadata": {},
   "source": [
    "## Tokenization and model fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b7f25a-1104-4a11-ba19-0a83b4dc598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- GLOBAL HYPERPARAMETERS ---\n",
    "NUM_LABELS = 2\n",
    "LEARNING_RATE = 2e-5\n",
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 3\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# List of models to run the experiment on\n",
    "MODEL_NAMES = [\n",
    "    \"abhinand/MedEmbed-large-v0.1\",\n",
    "    \"emilyalsentzer/Bio_ClinicalBERT\",\n",
    "    \"medicalai/ClinicalBERT\"\n",
    "]\n",
    "\n",
    "# --- 1. HELPER FUNCTION: METRICS ---\n",
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Computes AUROC, F1-Score, and other standard metrics for binary classification.\n",
    "    \"\"\"\n",
    "    preds_logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    labels = p.label_ids\n",
    "    \n",
    "    # Get predicted class (0 or 1)\n",
    "    preds = np.argmax(preds_logits, axis=1)\n",
    "    \n",
    "    # Get probabilities for the positive class (required for AUROC)\n",
    "    probas = torch.nn.functional.softmax(torch.tensor(preds_logits), dim=-1).numpy()[:, 1]\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    try:\n",
    "        # AUROC (Area Under the Receiver Operating Characteristic Curve)\n",
    "        roc_auc = roc_auc_score(labels, probas)\n",
    "    except ValueError:\n",
    "        # Handle case where only one class is present\n",
    "        roc_auc = 0.0\n",
    "        \n",
    "    # Precision, Recall, F1 for the positive class (1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average='binary', pos_label=1, zero_division=0 # Set zero_division=0 for safe calculations\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        'roc_auc': roc_auc,\n",
    "        'f1_score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': (preds == labels).mean(),\n",
    "    }\n",
    "\n",
    "def tokenize(model_name, train_X, train_y, val_X, val_y, test_X, test_y):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # B. Define Tokenization Parameters\n",
    "    MAX_LENGTH = 512 # Max length for standard BERT, consider increasing this if notes are very long\n",
    "    TRUNCATION = True\n",
    "    PADDING = 'max_length'\n",
    "    \n",
    "    # C. Function to Encode a Split\n",
    "    def encode_data(texts, labels):\n",
    "        \"\"\"Encodes text data and converts it into a PyTorch TensorDataset.\"\"\"\n",
    "        # Tokenize the texts\n",
    "        encodings = tokenizer(\n",
    "            texts,\n",
    "            max_length=MAX_LENGTH,\n",
    "            truncation=TRUNCATION,\n",
    "            padding=PADDING,\n",
    "            return_tensors='pt' # Return PyTorch tensors\n",
    "        )\n",
    "    \n",
    "        # Convert labels to PyTorch tensor\n",
    "        labels_tensor = torch.tensor(labels)\n",
    "    \n",
    "        # Create the TensorDataset\n",
    "        # The keys 'input_ids', 'attention_mask', and 'token_type_ids' are standard for BERT\n",
    "        dataset = TensorDataset(\n",
    "            encodings['input_ids'],\n",
    "            encodings['attention_mask'],\n",
    "            labels_tensor\n",
    "        )\n",
    "        return dataset\n",
    "    \n",
    "    # D. Encode All Splits\n",
    "    train_dataset = encode_data(train_X, train_y)\n",
    "    val_dataset = encode_data(val_X, val_y)\n",
    "    test_dataset = encode_data(test_X, test_y)\n",
    "    \n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Train Dataset (input_ids, attention_mask, labels): {train_dataset.tensors[0].shape}, {train_dataset.tensors[1].shape}, {train_dataset.tensors[2].shape}\")\n",
    "    print(f\"Validation Dataset: {val_dataset.tensors[0].shape}, {val_dataset.tensors[1].shape}, {val_dataset.tensors[2].shape}\")\n",
    "    print(f\"Test Dataset: {test_dataset.tensors[0].shape}, {test_dataset.tensors[1].shape}, {test_dataset.tensors[2].shape}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    train_dataset_hf = convert_tensor_dataset_to_hf_dataset(train_dataset)\n",
    "    val_dataset_hf = convert_tensor_dataset_to_hf_dataset(val_dataset)\n",
    "    test_dataset_hf = convert_tensor_dataset_to_hf_dataset(test_dataset)\n",
    "\n",
    "    return train_dataset_hf, val_dataset_hf, test_dataset_hf\n",
    "\n",
    "# --- 2. HELPER FUNCTION: DATA CONVERSION ---\n",
    "# NOTE: This assumes 'train_dataset', 'val_dataset', and 'test_dataset' \n",
    "# are available as PyTorch TensorDataset objects in the scope.\n",
    "def convert_tensor_dataset_to_hf_dataset(tensor_dataset):\n",
    "    \"\"\"Converts a PyTorch TensorDataset to a Hugging Face Dataset.\"\"\"\n",
    "    \n",
    "    # Extract the tensors: (input_ids, attention_mask, labels)\n",
    "    input_ids = tensor_dataset.tensors[0].numpy()\n",
    "    attention_mask = tensor_dataset.tensors[1].numpy()\n",
    "    labels = tensor_dataset.tensors[2].numpy()\n",
    "\n",
    "    data_dict = {\n",
    "        'input_ids': input_ids.tolist(),\n",
    "        'attention_mask': attention_mask.tolist(),\n",
    "        'labels': labels.tolist()\n",
    "    }\n",
    "    \n",
    "    hf_dataset = Dataset.from_dict(data_dict)\n",
    "    \n",
    "    # Ensure correct torch tensor types for the model input\n",
    "    def format_tensors(example):\n",
    "        example['input_ids'] = torch.tensor(example['input_ids'], dtype=torch.long)\n",
    "        example['attention_mask'] = torch.tensor(example['attention_mask'], dtype=torch.long)\n",
    "        example['labels'] = torch.tensor(example['labels'], dtype=torch.long)\n",
    "        return example\n",
    "        \n",
    "    hf_dataset = hf_dataset.map(format_tensors, batched=True)\n",
    "    \n",
    "    return hf_dataset\n",
    "\n",
    "\n",
    "# --- 3. MAIN EXPERIMENT FUNCTION ---\n",
    "def run_model_experiment(model_name, train_data, val_data, test_data, device):\n",
    "    \"\"\"\n",
    "    Initializes, fine-tunes, and evaluates a specific Hugging Face model.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"STARTING EXPERIMENT FOR MODEL: {model_name}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # A. Model Initialization\n",
    "    # We use AutoModelForSequenceClassification to load BERT with a classification head\n",
    "    try:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=NUM_LABELS,\n",
    "            ignore_mismatched_sizes=True, # Ignore mismatched sizes if classification head changes\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_name}: {e}\")\n",
    "        return {\"Model\": model_name, \"Error\": \"Failed to load model\"}\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    # B. Define Training Arguments (Dynamic Output Directory)\n",
    "    # Create a clean folder name for results\n",
    "    model_safe_name = model_name.replace(\"/\", \"__\").replace(\"-\", \"_\")\n",
    "    output_dir = f'./results_{model_safe_name}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,                           # Dynamic output directory\n",
    "        num_train_epochs=NUM_EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'./logs_{model_safe_name}',         # Dynamic logging directory\n",
    "        logging_steps=500,\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"roc_auc\",\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        save_total_limit=1,                              # Limit saves to only the best model\n",
    "        report_to=\"none\",                                 # Prevents need for external logging tools like WandB\n",
    "        gradient_accumulation_steps=2\n",
    "    )\n",
    "\n",
    "    # C. Setup and Run Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    print(\"Starting Fine-Tuning...\")\n",
    "    trainer.train()\n",
    "    print(\"Fine-tuning complete. Best model loaded.\")\n",
    "\n",
    "    # D. Final Evaluation on Test Set\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Final Evaluation on the Test Set\")\n",
    "    print(\"=\"*50)\n",
    "    test_results = trainer.evaluate(test_data)\n",
    "    \n",
    "    # Prepare results for comparison\n",
    "    final_results = {\n",
    "        'Model': model_name,\n",
    "        'Test_Accuracy': test_results.get('eval_accuracy'),\n",
    "        'Test_F1': test_results.get('eval_f1_score'),\n",
    "        'Test_AUROC': test_results.get('eval_roc_auc'),\n",
    "    }\n",
    "\n",
    "    print(\"Test Results:\")\n",
    "    for key, value in final_results.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "            \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ce76c-5af9-4e26-8a6d-5aa31de29d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPARISON_RESULTS = []\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    # Pass the converted Hugging Face datasets\n",
    "    train_dataset_hf, val_dataset_hf, test_dataset_hf = tokenize(model_name, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    results = run_model_experiment(model_name, \n",
    "                                   train_dataset_hf, \n",
    "                                   val_dataset_hf, \n",
    "                                   test_dataset_hf, \n",
    "                                   DEVICE)\n",
    "    COMPARISON_RESULTS.append(results)\n",
    "\n",
    "# Print Summary Table (Placeholder structure for final summary)\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"FINAL MODEL COMPARISON SUMMARY\")\n",
    "print(\"#\"*80)\n",
    "for res in COMPARISON_RESULTS:\n",
    "    print(f\"Model: {res.get('Model'):<40} | Accuracy: {res.get('Test_Accuracy', 'N/A'):.4f} | F1: {res.get('Test_F1', 'N/A'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a1789b-ce42-4220-87b2-1746510f8ae9",
   "metadata": {},
   "source": [
    "## preserving embeddings for future interpretability studies (ongoing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078864b-6a60-4ec5-8e4b-94c6de9c43df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_embeddings(model_name, dataset_hf, device, batch_size, output_file_prefix):\n",
    "    \"\"\"\n",
    "    Loads the base encoder model, extracts the [CLS] token embeddings for a dataset,\n",
    "    and saves the embeddings and labels to a NumPy .npy file.\n",
    "    \n",
    "    Returns: The path to the saved file.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"STARTING EMBEDDING EXTRACTION FOR MODEL: {model_name}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # A. Load the base model and tokenizer\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name) # Load the tokenizer \n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval() \n",
    "\n",
    "    # B. Setup Data Collator and DataLoader\n",
    "    # The collator groups samples into batches and converts them to tensors\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "    \n",
    "    # We use a standard DataLoader, passing the collator to handle the batching\n",
    "    data_loader = DataLoader(\n",
    "        dataset_hf, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=False, \n",
    "        collate_fn=data_collator # CRITICAL CHANGE\n",
    "    )\n",
    "\n",
    "    all_embeddings = []\n",
    "    all_labels = []\n",
    "\n",
    "    # C. Inference Loop\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Extracting Embeddings\"):\n",
    "            \n",
    "            # Inputs to the model (input_ids and attention_mask are now tensors)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            \n",
    "            # Labels are stored separately\n",
    "            labels = batch['labels'].to(device)\n",
    "            # --------------------------------------------------------------------------\n",
    "\n",
    "            # Pass through the model\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Extract the [CLS] token embedding (first token, index 0)\n",
    "            # Shape (batch_size, hidden_size)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            \n",
    "            all_embeddings.append(cls_embeddings)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "\n",
    "    # D. Aggregate and Save\n",
    "    final_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "    final_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Save to file\n",
    "    output_path = f\"{output_file_prefix}_embeddings_features.npy\"\n",
    "    # Ensure all required numpy imports are present in the script\n",
    "    np.save(output_path, {'X': final_embeddings, 'y': final_labels}) \n",
    "    \n",
    "    print(f\"Extraction complete. Saved data to: {output_path}\")\n",
    "    print(f\"Features shape (Embeddings): {final_embeddings.shape}\")\n",
    "    print(f\"Target shape (Labels): {final_labels.shape}\")\n",
    "    \n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a530a38-8af9-4a57-af4f-343cd87bc889",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPARISON_RESULTS = []\n",
    "EMBEDDING_FILE_PATHS = [] # Store the paths to the saved embedding files\n",
    "\n",
    "for model_name in MODEL_NAMES:\n",
    "    \n",
    "    # 2. Extract embeddings from the TEST set using the base model\n",
    "    model_safe_name = model_name.split('/')[-1]\n",
    "    \n",
    "    embedding_file = extract_and_save_embeddings(\n",
    "        model_name=model_name,\n",
    "        dataset_hf=test_dataset_hf,\n",
    "        device=DEVICE,\n",
    "        batch_size=BATCH_SIZE * 2, # Can use a larger batch for inference\n",
    "        output_file_prefix=model_safe_name\n",
    "    )\n",
    "    EMBEDDING_FILE_PATHS.append(embedding_file)\n",
    "\n",
    "print(\"\\nEmbedding extraction finished. Proceed to train separate XGBoost models.\")\n",
    "print(f\"Saved Files: {EMBEDDING_FILE_PATHS}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cleanenv)",
   "language": "python",
   "name": "cleanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
